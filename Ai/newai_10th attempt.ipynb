{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Lambda, Dropout, BatchNormalization, Add, GlobalAveragePooling2D, concatenate\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array, ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, Callback\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load images from a folder\n",
    "def load_images_from_folder(folder, augmentation=False):\n",
    "    images = []\n",
    "    datagen = ImageDataGenerator(rotation_range=10, width_shift_range=0.1, height_shift_range=0.1,\n",
    "                                 shear_range=0.1, zoom_range=0.1, horizontal_flip=True, fill_mode='nearest') if augmentation else None\n",
    "\n",
    "    for filename in os.listdir(folder):\n",
    "        img_path = os.path.join(folder, filename)\n",
    "        img = preprocess_image(img_path)\n",
    "        if img is not None:\n",
    "            if augmentation:\n",
    "                img = np.expand_dims(img, axis=0)\n",
    "                for batch in datagen.flow(img, batch_size=1):\n",
    "                    images.append(batch[0])\n",
    "                    break\n",
    "            else:\n",
    "                images.append(img)\n",
    "\n",
    "    return np.array(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image_path):\n",
    "    # Load the image in grayscale\n",
    "    img = load_img(image_path, color_mode='grayscale', target_size=(128, 128))\n",
    "    img = img_to_array(img).astype('uint8')\n",
    "    \n",
    "    # Apply edge detection\n",
    "    edges = cv2.Canny(img, threshold1=30, threshold2=100)\n",
    "    \n",
    "    # Dilate the edges to broaden the lines\n",
    "    kernel = np.ones((3,3), np.uint8)\n",
    "    edges = cv2.dilate(edges, kernel, iterations=1)\n",
    "    \n",
    "    # Invert the edges: detected edges should be black, and the rest should be white\n",
    "    edges = cv2.bitwise_not(edges)\n",
    "    \n",
    "    # Normalize the image\n",
    "    edges = edges / 255.0\n",
    "    edges = np.expand_dims(edges, axis=-1)\n",
    "    \n",
    "    return edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images_from_folder(folder):\n",
    "    images = []\n",
    "    for filename in os.listdir(folder):\n",
    "        img_path = os.path.join(folder, filename)\n",
    "        if img_path is not None:\n",
    "            processed_img = preprocess_image(img_path)\n",
    "            images.append(processed_img)\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(base_path):\n",
    "    X = []\n",
    "    y = []\n",
    "    for person_id in range(1, 65):  # Assuming you have 64 persons\n",
    "        if person_id in [5,7,8,10,11]:\n",
    "            continue\n",
    "        person_id = str(person_id).zfill(3)\n",
    "        real_folder = os.path.join(base_path, person_id)\n",
    "        forge_folder = os.path.join(base_path, f\"{person_id}_forg\")\n",
    "\n",
    "        real_images = load_images_from_folder(real_folder)\n",
    "        forge_images = load_images_from_folder(forge_folder)\n",
    "\n",
    "        for img in real_images:\n",
    "            X.append(img)\n",
    "            y.append(0)  # Label for genuine signatures\n",
    "\n",
    "        for img in forge_images:\n",
    "            X.append(img)\n",
    "            y.append(1)  # Label for forged signatures\n",
    "\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    X = X / 255.0  # Normalize the images\n",
    "    X = X.reshape(-1, 128, 128, 1)  # Reshape for the CNN\n",
    "    return X, y\n",
    "\n",
    "base_path = 'sign_data/train'\n",
    "X, y = create_dataset(base_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display a single image before and after preprocessing\n",
    "def display_image_before_after(file_path):\n",
    "    img = cv2.imread(file_path, cv2.IMREAD_GRAYSCALE)\n",
    "    img_resized = cv2.resize(img, (128, 128))\n",
    "    processed_img = preprocess_image(file_path)\n",
    "    \n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.title('Original Image')\n",
    "    plt.imshow(img_resized, cmap='gray')\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.title('Processed Image')\n",
    "    plt.imshow(processed_img, cmap='gray')\n",
    "    plt.show()\n",
    "\n",
    "# Example image display\n",
    "example_image_path = 'sign_data/train/001/001_01.PNG'  # Provide a valid image path here\n",
    "display_image_before_after(example_image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "def build_complex_model():\n",
    "    model = Sequential()\n",
    "    \n",
    "    # First convolutional block\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu', input_shape=(128, 128, 1)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    \n",
    "    # Second convolutional block\n",
    "    model.add(Conv2D(256, (3, 3), activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    \n",
    "    # Third convolutional block\n",
    "    model.add(Conv2D(512, (3, 3), activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    \n",
    "    # Fourth convolutional block\n",
    "    model.add(Conv2D(1024, (3, 3), activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    \n",
    "    # Flatten and dense layers\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(2048, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    optimizer = Adam(learning_rate=0.0001)\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = build_complex_model()\n",
    "\n",
    "# Data augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    zoom_range=0.15,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.15,\n",
    "    fill_mode=\"nearest\",\n",
    "    horizontal_flip=True,\n",
    "    validation_split=0.2\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "train_generator = datagen.flow(X_train, y_train, batch_size=32, subset='training')\n",
    "validation_generator = datagen.flow(X_train, y_train, batch_size=32, subset='validation')\n",
    "\n",
    "history = model.fit(train_generator, epochs=50, validation_data=validation_generator)\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Accuracy: {test_acc}\")\n",
    "\n",
    "# Save the model using Keras method\n",
    "model.save('complex_signature_verification_model_improved.keras')\n",
    "\n",
    "# Plot the model summary\n",
    "plot_model(model, to_file='model_summary.png', show_shapes=True, show_layer_names=True)\n",
    "\n",
    "# Print the model summary\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-29 01:48:27.142860: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-29 01:48:27.163693: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2251] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "import numpy as np\n",
    "\n",
    "# Load the saved model\n",
    "model = load_model('complex_signature_verification_model123.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image1(image_path):\n",
    "    processed_img = preprocess_image(image_path)\n",
    "    processed_img = processed_img / 255.0\n",
    "    processed_img = processed_img.reshape(1, 128, 128, 1)\n",
    "    return processed_img\n",
    "\n",
    "def predict_signature(model, real_signature_path, test_signature_path):\n",
    "    real_img = preprocess_image1(real_signature_path)\n",
    "    test_img = preprocess_image1(test_signature_path)\n",
    "    \n",
    "    real_pred = model.predict(real_img)\n",
    "    test_pred = model.predict(test_img)\n",
    "    \n",
    "    difference = np.abs(real_pred - test_pred)\n",
    "    return difference\n",
    "\n",
    "# Example usage\n",
    "real_signature_path = 'img1.jpeg'  # Provide a valid image path\n",
    "test_signature_path = 'img1.jpeg'  # Provide a valid image path\n",
    "difference = predict_signature(model, real_signature_path, test_signature_path)\n",
    "print(f\"Difference: {difference}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpg67gns4_/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpg67gns4_/assets\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "with open('complex_signature_verification_model123.tflite', 'wb') as f:\n",
    "    f.write(tflite_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
